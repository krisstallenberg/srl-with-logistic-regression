{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def provide_confusion_matrix(GoldLabel, PredictLabel, label_set):\n",
    "    \"\"\"\n",
    "    use `sklearn.metric confusion_matrix` to create confusion matrix of model predict.\n",
    "    and `sklearn.metric ConfusionMatrixDisplay` to display created confusion matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    GoldLabel : list\n",
    "        list of all Gold labels\n",
    "    PredictLabel : list\n",
    "        list of all Prediction labels\n",
    "    label_set : list\n",
    "        list of all classes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Confusion matrix\n",
    "    \"\"\"\n",
    "    cf_matrix = confusion_matrix(GoldLabel, PredictLabel) # create a confusion matrix with gold and predicts\n",
    "    print(cf_matrix) # print confusion_matrix as text\n",
    "    display = ConfusionMatrixDisplay(confusion_matrix=cf_matrix, display_labels=label_set) # create graphical confusion_matrix\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    # display.plot(ax=ax)\n",
    "    display.plot(ax =ax) # show confusion_matrix\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    return cf_matrix # return confusion_matrix (maybe useful later)\n",
    "\n",
    "def calculate_precision_recall_f1score(GoldLabel, PredictLabel, label_set): # function get gold and predict and set of labels\n",
    "    \"\"\"\n",
    "    use `sklearn.metric classification_report` to get report of model predict.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    GoldLabel : list\n",
    "        list of all Gold labels\n",
    "    PredictLabel : list\n",
    "        list of all Prediction labels\n",
    "    label_set : list\n",
    "        list of all classes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Classification report\n",
    "    \"\"\"\n",
    "    report = classification_report(GoldLabel, PredictLabel, digits = 3, target_names=label_set) # calculate report\n",
    "    print(report) # print report\n",
    "    return report # return report (maybe useful later)\n",
    "\n",
    "# def evaluation_model(GoldLabel, PredictLabel): # get gold and predict\n",
    "def evaluation_model(GoldLabel, PredictLabel): # get gold and predict\n",
    "    \"\"\"\n",
    "    Evaluation models by call `calculate_precision_recall_f1score` and `provide_confusion_matrix` functions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    GoldLabel : list\n",
    "        list of all Gold labels\n",
    "    PredictLabel : list\n",
    "        list of all Prediction labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Classification report and Confusion matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # GoldLabel = extract_golds_from_data(data)\n",
    "\n",
    "    label_set = sorted(set(GoldLabel)) # find uniqe lables in gold\n",
    "    print(label_set)\n",
    "\n",
    "    print('precision_recall_f1-score')\n",
    "    report = calculate_precision_recall_f1score(GoldLabel, PredictLabel, label_set) # calculate_precision_recall_f1score\n",
    "\n",
    "    print('Confusion matrix')\n",
    "    cf_matrix = provide_confusion_matrix(GoldLabel, PredictLabel, label_set) # provide_confusion_matrix\n",
    "\n",
    "    return report, cf_matrix # return report and cf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_data(file_path):\n",
    "    with open(file_path.replace('.conllu', '.preprocessed.pkl'), 'rb') as pickle_file:\n",
    "        return pickle.load(pickle_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = 'en_ewt-up-train.conllu'\n",
    "train_data = load_data(train_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for sents in train_data:\n",
    "    for word in sents:\n",
    "        for f in word['features']:\n",
    "            word[f]=word['features'][f]\n",
    "        word_list.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1028137\n"
     ]
    }
   ],
   "source": [
    "print(len(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>features</th>\n",
       "      <th>head</th>\n",
       "      <th>dependency_relation</th>\n",
       "      <th>dependency_graph</th>\n",
       "      <th>miscellaneous</th>\n",
       "      <th>...</th>\n",
       "      <th>Case</th>\n",
       "      <th>Person</th>\n",
       "      <th>NumType</th>\n",
       "      <th>Voice</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Poss</th>\n",
       "      <th>Reflex</th>\n",
       "      <th>Typo</th>\n",
       "      <th>Foreign</th>\n",
       "      <th>Abbr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Al</td>\n",
       "      <td>Al</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>{'Number': 'Sing', 'embedding': [0.0, 0.0, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>0:root</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>HYPH</td>\n",
       "      <td>{'embedding': [-0.52482, -0.31963, -0.11898, -...</td>\n",
       "      <td>1</td>\n",
       "      <td>punct</td>\n",
       "      <td>1:punct</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Zaman</td>\n",
       "      <td>Zaman</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>{'Number': 'Sing', 'embedding': [0.0, 0.0, 0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>flat</td>\n",
       "      <td>1:flat</td>\n",
       "      <td>_</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:</td>\n",
       "      <td>{'embedding': [0.43607, 1.5253, -0.11532, 0.33...</td>\n",
       "      <td>1</td>\n",
       "      <td>punct</td>\n",
       "      <td>1:punct</td>\n",
       "      <td>_</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>American</td>\n",
       "      <td>american</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>{'Degree': 'Pos', 'embedding': [0.15796, 0.012...</td>\n",
       "      <td>6</td>\n",
       "      <td>amod</td>\n",
       "      <td>6:amod</td>\n",
       "      <td>_</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  id      form     lemma   upos  xpos  \\\n",
       "0  1        Al        Al  PROPN   NNP   \n",
       "1  2         -         -  PUNCT  HYPH   \n",
       "2  3     Zaman     Zaman  PROPN   NNP   \n",
       "3  4         :         :  PUNCT     :   \n",
       "4  5  American  american    ADJ    JJ   \n",
       "\n",
       "                                            features head dependency_relation  \\\n",
       "0  {'Number': 'Sing', 'embedding': [0.0, 0.0, 0.0...    0                root   \n",
       "1  {'embedding': [-0.52482, -0.31963, -0.11898, -...    1               punct   \n",
       "2  {'Number': 'Sing', 'embedding': [0.0, 0.0, 0.0...    1                flat   \n",
       "3  {'embedding': [0.43607, 1.5253, -0.11532, 0.33...    1               punct   \n",
       "4  {'Degree': 'Pos', 'embedding': [0.15796, 0.012...    6                amod   \n",
       "\n",
       "  dependency_graph  miscellaneous  ... Case Person NumType Voice Gender Poss  \\\n",
       "0           0:root  SpaceAfter=No  ...  NaN    NaN     NaN   NaN    NaN  NaN   \n",
       "1          1:punct  SpaceAfter=No  ...  NaN    NaN     NaN   NaN    NaN  NaN   \n",
       "2           1:flat              _  ...  NaN    NaN     NaN   NaN    NaN  NaN   \n",
       "3          1:punct              _  ...  NaN    NaN     NaN   NaN    NaN  NaN   \n",
       "4           6:amod              _  ...  NaN    NaN     NaN   NaN    NaN  NaN   \n",
       "\n",
       "  Reflex  Typo  Foreign Abbr  \n",
       "0    NaN   NaN      NaN  NaN  \n",
       "1    NaN   NaN      NaN  NaN  \n",
       "2    NaN   NaN      NaN  NaN  \n",
       "3    NaN   NaN      NaN  NaN  \n",
       "4    NaN   NaN      NaN  NaN  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "train_df = pd.DataFrame(word_list)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['id','features', 'Definite', 'PronType', 'Number', 'Mood','Person', 'Tense', 'VerbForm','head','dependency_graph',\n",
    "                                  'miscellaneous','head_pp_feature','prev_token_morph_features', 'next_token_morph_features','embedding_head', 'punct_extracted',\n",
    "                                  'NumType','Degree', 'Case', 'Gender', 'Poss', 'Voice', 'Foreign', 'Reflex', 'Typo','num_of_children','Abbr','propbank_arg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>dependency_relation</th>\n",
       "      <th>predicate</th>\n",
       "      <th>argument</th>\n",
       "      <th>embedding</th>\n",
       "      <th>pos_extracted</th>\n",
       "      <th>position_rel2pred</th>\n",
       "      <th>head_pos</th>\n",
       "      <th>dep_path</th>\n",
       "      <th>cosine_similarity_w_predicate</th>\n",
       "      <th>pos_misc_feature</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al</td>\n",
       "      <td>Al</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>root</td>\n",
       "      <td>kill.01</td>\n",
       "      <td>_</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Before</td>\n",
       "      <td>root</td>\n",
       "      <td>_</td>\n",
       "      <td>[[0.0]]</td>\n",
       "      <td>PROPN_no_space</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>HYPH</td>\n",
       "      <td>punct</td>\n",
       "      <td>kill.01</td>\n",
       "      <td>_</td>\n",
       "      <td>[-0.52482, -0.31963, -0.11898, -0.62672, 0.043...</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>Before</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[HYPH]</td>\n",
       "      <td>[[0.2082173]]</td>\n",
       "      <td>PUNCT_no_space</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zaman</td>\n",
       "      <td>Zaman</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>flat</td>\n",
       "      <td>kill.01</td>\n",
       "      <td>_</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Before</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[NNP]</td>\n",
       "      <td>[[0.0]]</td>\n",
       "      <td>PROPN_space</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:</td>\n",
       "      <td>punct</td>\n",
       "      <td>kill.01</td>\n",
       "      <td>_</td>\n",
       "      <td>[0.43607, 1.5253, -0.11532, 0.33558, 0.36617, ...</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>Before</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[:]</td>\n",
       "      <td>[[0.3154642]]</td>\n",
       "      <td>PUNCT_space</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American</td>\n",
       "      <td>american</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>kill.01</td>\n",
       "      <td>_</td>\n",
       "      <td>[0.15796, 0.012358, 0.1681, -0.81207, 0.34308,...</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>Before</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[JJ, NNS, VBD]</td>\n",
       "      <td>[[0.27067295]]</td>\n",
       "      <td>ADJ_space</td>\n",
       "      <td>NORP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       form     lemma   upos  xpos dependency_relation predicate argument  \\\n",
       "0        Al        Al  PROPN   NNP                root   kill.01        _   \n",
       "1         -         -  PUNCT  HYPH               punct   kill.01        _   \n",
       "2     Zaman     Zaman  PROPN   NNP                flat   kill.01        _   \n",
       "3         :         :  PUNCT     :               punct   kill.01        _   \n",
       "4  American  american    ADJ    JJ                amod   kill.01        _   \n",
       "\n",
       "                                           embedding pos_extracted  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...         PROPN   \n",
       "1  [-0.52482, -0.31963, -0.11898, -0.62672, 0.043...         PUNCT   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...         PROPN   \n",
       "3  [0.43607, 1.5253, -0.11532, 0.33558, 0.36617, ...         PUNCT   \n",
       "4  [0.15796, 0.012358, 0.1681, -0.81207, 0.34308,...           ADJ   \n",
       "\n",
       "  position_rel2pred head_pos        dep_path cosine_similarity_w_predicate  \\\n",
       "0            Before     root               _                       [[0.0]]   \n",
       "1            Before    PROPN          [HYPH]                 [[0.2082173]]   \n",
       "2            Before    PROPN           [NNP]                       [[0.0]]   \n",
       "3            Before    PROPN             [:]                 [[0.3154642]]   \n",
       "4            Before     NOUN  [JJ, NNS, VBD]                [[0.27067295]]   \n",
       "\n",
       "  pos_misc_feature     ner  \n",
       "0   PROPN_no_space  PERSON  \n",
       "1   PUNCT_no_space       _  \n",
       "2      PROPN_space       _  \n",
       "3      PUNCT_space       _  \n",
       "4        ADJ_space    NORP  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_golds = train_df['argument'].copy()\n",
    "train_df= train_df.drop(columns =['argument'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>dependency_relation</th>\n",
       "      <th>predicate</th>\n",
       "      <th>embedding</th>\n",
       "      <th>pos_extracted</th>\n",
       "      <th>position_rel2pred</th>\n",
       "      <th>head_pos</th>\n",
       "      <th>dep_path</th>\n",
       "      <th>cosine_similarity_w_predicate</th>\n",
       "      <th>pos_misc_feature</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al</td>\n",
       "      <td>Al</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>root</td>\n",
       "      <td>kill.01</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Before</td>\n",
       "      <td>root</td>\n",
       "      <td>_</td>\n",
       "      <td>[[0.0]]</td>\n",
       "      <td>PROPN_no_space</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>HYPH</td>\n",
       "      <td>punct</td>\n",
       "      <td>kill.01</td>\n",
       "      <td>[-0.52482, -0.31963, -0.11898, -0.62672, 0.043...</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>Before</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[HYPH]</td>\n",
       "      <td>[[0.2082173]]</td>\n",
       "      <td>PUNCT_no_space</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zaman</td>\n",
       "      <td>Zaman</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>flat</td>\n",
       "      <td>kill.01</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Before</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[NNP]</td>\n",
       "      <td>[[0.0]]</td>\n",
       "      <td>PROPN_space</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:</td>\n",
       "      <td>punct</td>\n",
       "      <td>kill.01</td>\n",
       "      <td>[0.43607, 1.5253, -0.11532, 0.33558, 0.36617, ...</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>Before</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[:]</td>\n",
       "      <td>[[0.3154642]]</td>\n",
       "      <td>PUNCT_space</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American</td>\n",
       "      <td>american</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>kill.01</td>\n",
       "      <td>[0.15796, 0.012358, 0.1681, -0.81207, 0.34308,...</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>Before</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[JJ, NNS, VBD]</td>\n",
       "      <td>[[0.27067295]]</td>\n",
       "      <td>ADJ_space</td>\n",
       "      <td>NORP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       form     lemma   upos  xpos dependency_relation predicate  \\\n",
       "0        Al        Al  PROPN   NNP                root   kill.01   \n",
       "1         -         -  PUNCT  HYPH               punct   kill.01   \n",
       "2     Zaman     Zaman  PROPN   NNP                flat   kill.01   \n",
       "3         :         :  PUNCT     :               punct   kill.01   \n",
       "4  American  american    ADJ    JJ                amod   kill.01   \n",
       "\n",
       "                                           embedding pos_extracted  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...         PROPN   \n",
       "1  [-0.52482, -0.31963, -0.11898, -0.62672, 0.043...         PUNCT   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...         PROPN   \n",
       "3  [0.43607, 1.5253, -0.11532, 0.33558, 0.36617, ...         PUNCT   \n",
       "4  [0.15796, 0.012358, 0.1681, -0.81207, 0.34308,...           ADJ   \n",
       "\n",
       "  position_rel2pred head_pos        dep_path cosine_similarity_w_predicate  \\\n",
       "0            Before     root               _                       [[0.0]]   \n",
       "1            Before    PROPN          [HYPH]                 [[0.2082173]]   \n",
       "2            Before    PROPN           [NNP]                       [[0.0]]   \n",
       "3            Before    PROPN             [:]                 [[0.3154642]]   \n",
       "4            Before     NOUN  [JJ, NNS, VBD]                [[0.27067295]]   \n",
       "\n",
       "  pos_misc_feature     ner  \n",
       "0   PROPN_no_space  PERSON  \n",
       "1   PUNCT_no_space       _  \n",
       "2      PROPN_space       _  \n",
       "3      PUNCT_space       _  \n",
       "4        ADJ_space    NORP  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dict = train_df.to_dict(orient='records')\n",
    "for row in train_data_dict:\n",
    "    row['embedding'] = str(row['embedding'])\n",
    "    row['cosine_similarity_w_predicate'] = str(row['cosine_similarity_w_predicate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = DictVectorizer()\n",
    "logreg = LogisticRegression()\n",
    "X_transformed = vec.fit_transform(train_data_dict)\n",
    "model = logreg.fit(X_transformed, train_golds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = 'en_ewt-up-test.conllu'\n",
    "test_data = load_data(test_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_test = []\n",
    "for sents in test_data:\n",
    "    for word in sents:\n",
    "        for f in word['features']:\n",
    "            word[f]=word['features'][f]\n",
    "        word_list_test.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(word_list_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(word_list)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(columns=['id','features', 'Definite', 'PronType', 'Number', 'Mood','Person', 'Tense', 'VerbForm','head','dependency_graph',\n",
    "                                  'miscellaneous','head_pp_feature','prev_token_morph_features', 'next_token_morph_features','embedding_head', 'punct_extracted',\n",
    "                                  'NumType','Degree', 'Case', 'Gender', 'Poss', 'Voice', 'Foreign', 'Reflex', 'Typo','num_of_children','Abbr','propbank_arg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golds_test = df_test['argument'].copy()\n",
    "df_test= df_test.drop(columns =['argument'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_test = df_test.to_dict(orient='records')\n",
    "for row in data_dict_test:\n",
    "    row['embedding'] = str(row['embedding'])\n",
    "    row['cosine_similarity_w_predicate'] = str(row['cosine_similarity_w_predicate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = vec.transform(data_dict_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_model(golds_test,preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
